{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run hypothesis.ipynb\n",
    "\n",
    "#Cost function, default lambda (regularization) 0\n",
    "def computeCost(theta, x, y, lambd = 0.): \n",
    "    \"\"\"\n",
    "    theta_start is an n- dimensional vector of initial theta guess\n",
    "    X is matrix with n- columns and m- rows\n",
    "    y is a matrix with m- rows and 1 column\n",
    "    Note this includes regularization, if you set mylambda to nonzero\n",
    "    For the first part of the homework, the default 0. is used for mylambda\n",
    "    \"\"\"\n",
    "    # transposed array of accepted/not (y)\n",
    "    transposedY = np.array(y).T\n",
    "    hypothesisOfThetaX = hypothesis(theta, x)\n",
    "    # multiple negative transposedY and log of hypothesis of theta, x \n",
    "    term1 = np.dot(-transposedY, np.log(hypothesisOfThetaX))\n",
    "    # transposed (1 - y) multiplied by log of hypothesis of theta, x\n",
    "    term2 = np.dot((1 - np.array(y)).T, np.log(1 - hypothesisOfThetaX))\n",
    "    regterm = (lambd / 2) * np.sum(np.dot(theta[1:].T, theta[1:])) #Skip theta0\n",
    "    return float( (1./m) * ( np.sum(term1 - term2) + regterm ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
