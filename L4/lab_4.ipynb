{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "import scipy.misc\n",
    "import matplotlib.cm as cm\n",
    "import random\n",
    "import scipy.optimize\n",
    "import itertools\n",
    "from scipy.special import expit\n",
    "import sys\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"ex4data1.mat\"\n",
    "data_file = loadmat(file)\n",
    "initial_data = data_file[\"X\"]\n",
    "result = data_file[\"y\"]\n",
    "\n",
    "# insert column of 1's\n",
    "initial_data = np.insert(initial_data, 0, 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_matrix(array):\n",
    "    # get image size (we know that it will be a square image)\n",
    "    image_size = int(math.sqrt(array.shape[0]))\n",
    "    # take all from the first item (exclude 1's)\n",
    "    return array[1:].reshape(image_size, image_size).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = \"ex4weights.mat\"\n",
    "weight_file = loadmat(data_file)\n",
    "# theta_1 => size 25 x 401 \n",
    "# theta_2 => size 10 x 26\n",
    "theta_1, theta_2 = weight_file['Theta1'], weight_file['Theta2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer_size = 400 # amount of pixels in one image (without bias)\n",
    "hidden_layer_size = 25 # take 25 hidden layers because of the provided thetas\n",
    "output_layer_size = 10 # number of classes\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = pd.DataFrame(np.hstack((result, initial_data)))\n",
    "\n",
    "pd_train_data = data.sample(frac=0.8)\n",
    "pd_test_data = data.drop(pd_train_data.index)\n",
    "\n",
    "# Convert training and testing data from Pandas to NumPy format.\n",
    "train_data = pd_train_data.values\n",
    "test_data = pd_test_data.values\n",
    "\n",
    "# Extract training/test labels and features.\n",
    "num_training_examples = train_data.shape[0]\n",
    "x_train = train_data[:num_training_examples, 1:]\n",
    "y_train = train_data[:num_training_examples, [0]]\n",
    "\n",
    "x_test = test_data[:, 1:]\n",
    "y_test = test_data[:, [0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unroll(thetas):\n",
    "    theta_list = [ theta.flatten() for theta in thetas ]\n",
    "    combined = list(itertools.chain.from_iterable(theta_list))\n",
    "    assert len(combined) == (input_layer_size+1)*hidden_layer_size + \\\n",
    "                            (hidden_layer_size+1)*output_layer_size\n",
    "    return np.array(combined).reshape((len(combined),1))\n",
    "\n",
    "def reshape(unrolled):\n",
    "    theta1 = unrolled[:(input_layer_size+1)*hidden_layer_size] \\\n",
    "            .reshape((hidden_layer_size,input_layer_size+1))\n",
    "    theta2 = unrolled[(input_layer_size+1)*hidden_layer_size:] \\\n",
    "            .reshape((output_layer_size,hidden_layer_size+1))\n",
    "    \n",
    "    return [ theta1, theta2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost_function(unroll_thetas, x, y, lambd=0.):\n",
    "    #This is what will accumulate the total cost\n",
    "    total_cost = 0.\n",
    "    \n",
    "    thetas = reshape(unroll_thetas)\n",
    "    \n",
    "    m = x.shape[0]\n",
    "    \n",
    "    # Loop over the training points (rows in myX, already contain bias unit)\n",
    "    for index in range(m):\n",
    "        row = x[index]\n",
    "                \n",
    "        # First compute the hypothesis (this is a (10,1) vector\n",
    "        # of the hypothesis for each possible y-value)\n",
    "        # propagateForward returns (zs, activations) for each layer\n",
    "        # so propagateforward[-1][1] means \"activation for -1st (last) layer\"\n",
    "        \n",
    "        # get last layer result (hypothesis)\n",
    "        # [-1] => backwards indexing, [1] => layer output\n",
    "        hs = propagate_forward(row,thetas)[-1][1]\n",
    "\n",
    "        # Construct a 10x1 \"y\" vector with all zeros and only one \"1\" entry (hot-one encoding)\n",
    "        hot_one = np.zeros((10,1))\n",
    "        hot_one[int(y[index])-1] = 1\n",
    "        \n",
    "        # Compute the cost for this point and y-vector\n",
    "        cost = -hot_one.T.dot(np.log(hs))-(1-hot_one.T).dot(np.log(1-hs))\n",
    "     \n",
    "        # Accumulate the total cost\n",
    "        total_cost += cost\n",
    "  \n",
    "    # Normalize the total_cost, cast as float\n",
    "    total_cost = float(total_cost) / m\n",
    "    \n",
    "    # Compute the regularization term\n",
    "    total_reg = 0.\n",
    "    for theta in thetas:\n",
    "        total_reg += np.sum(theta*theta) #element-wise multiplication\n",
    "    total_reg *= float(lambd)/(2*m)\n",
    "        \n",
    "    return total_cost + total_reg     \n",
    "\n",
    "def propagate_forward(features, thetas):\n",
    "    input_output = []\n",
    "    for index in range(len(thetas)):  \n",
    "        theta = thetas[index]\n",
    "        \n",
    "        inputs = theta.dot(features).reshape((theta.shape[0], 1))\n",
    "        # sigmoid hypothesis\n",
    "        outputs = expit(inputs)\n",
    "        input_output.append((inputs, outputs))\n",
    "        if index == len(thetas)-1:\n",
    "            return np.array(input_output)\n",
    "        \n",
    "        features_bias = np.insert(outputs,0,1) # Add the bias unit\n",
    "        features = features_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29179609779189913"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thetas = unroll([theta_1, theta_2])\n",
    "\n",
    "# cost without regularization\n",
    "cost_function(thetas, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41286938664386796"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cost with regularization\n",
    "cost_function(thetas, x_train, y_train, 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(row, thetas, classes):\n",
    "    output = propagate_forward(row, thetas)\n",
    "    #-1 means last layer, 1 means \"a\" instead of \"z\"\n",
    "    return classes[np.argmax(output[-1][1])] \n",
    "\n",
    "def compute_accuracy(thetas, x, y):\n",
    "    classes = np.unique(result)\n",
    "    \n",
    "    n_correct, n_total = 0, x.shape[0]\n",
    "    for index in range(n_total):\n",
    "        if int(predict(x[index], thetas, classes)) == int(y[index]): \n",
    "            n_correct += 1\n",
    "    \n",
    "    return (100*(float(n_correct)/n_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97.575"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate percentage of correct classifications\n",
    "compute_accuracy([theta_1, theta_2], x_train, y_train)\n",
    "# it's a bit higher than the regular logistic regression (was ~95% on training data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    sigmoid = expit(z)\n",
    "    # derivative of the sigmoid action function\n",
    "    return sigmoid * (1 - sigmoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_weights():\n",
    "    epsilon_init = 0.10\n",
    "    \n",
    "    # randomize weight on input => hidden paths\n",
    "    theta_1 = np.random.rand(hidden_layer_size, input_layer_size+1) * 2 * epsilon_init - epsilon_init\n",
    "    # randomize weight on hidden => output paths\n",
    "    theta_2 = np.random.rand(output_layer_size, hidden_layer_size+1) * 2 * epsilon_init - epsilon_init\n",
    "\n",
    "    return theta_1, theta_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_propagate(unroll_thetas, x, y, lambd=0.):\n",
    "    #Note: the Delta matrices should include the bias unit\n",
    "    #The Delta matrices have the same shape as the theta matrices\n",
    "    Delta1 = np.zeros((hidden_layer_size,input_layer_size+1))\n",
    "    Delta2 = np.zeros((output_layer_size,hidden_layer_size+1))\n",
    "\n",
    "    thetas = reshape(unroll_thetas)\n",
    "    \n",
    "    # Loop over the training points (rows in myX, already contain bias unit)\n",
    "    m = x.shape[0]\n",
    "    for index in range(m):\n",
    "        row = x[index]\n",
    "        # reshape into a vector with 401 rows\n",
    "        a1 = row.reshape((input_layer_size+1,1))\n",
    "        # propagateForward returns (zs, activations) for each layer excluding the input layer\n",
    "        temp = propagate_forward(row,thetas)\n",
    "        z2 = temp[0][0]\n",
    "        a2 = temp[0][1]\n",
    "        z3 = temp[1][0]\n",
    "        a3 = temp[1][1]\n",
    "        hot_one = np.zeros((10,1))\n",
    "        hot_one[int(y[index])-1] = 1\n",
    "        \n",
    "        delta3 = a3 - hot_one \n",
    "        delta2 = thetas[1].T[1:,:].dot(delta3)*sigmoid_gradient(z2) #remove 0th element\n",
    "        a2 = np.insert(a2,0,1,axis=0)\n",
    "        Delta1 += delta2.dot(a1.T) #(25,1)x(1,401) = (25,401) (correct)\n",
    "        Delta2 += delta3.dot(a2.T) #(10,1)x(1,25) = (10,25) (should be 10,26)\n",
    "        \n",
    "    D1 = Delta1/float(m)\n",
    "    D2 = Delta2/float(m)\n",
    "    \n",
    "    #Regularization:\n",
    "    D1[:,1:] = D1[:,1:] + (float(lambd)/m)*thetas[0][:,1:]\n",
    "    D2[:,1:] = D2[:,1:] + (float(lambd)/m)*thetas[1][:,1:]\n",
    "    \n",
    "    return unroll([D1, D2]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back propagate gradients\n",
    "D1, D2 = reshape(back_propagate(thetas, x_train, y_train, lambd=0.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_check(thetas, ds, x, y, lambd=0.):\n",
    "    eps = 0.0001\n",
    "    \n",
    "    for theta_index in range(len(thetas)):\n",
    "        layer_weights = thetas[theta_index]\n",
    "        \n",
    "        for i in range(2):\n",
    "            for j in range(2):\n",
    "                row_index = int(np.random.rand()*layer_weights.shape[0])\n",
    "                column_index = int(np.random.rand()*layer_weights.shape[1])\n",
    "                \n",
    "                temp = thetas[theta_index][row_index][column_index]\n",
    "                minus_eps = thetas[theta_index][row_index][column_index] - eps\n",
    "                thetas[theta_index][row_index][column_index] = minus_eps\n",
    "                cost_low = cost_function(unroll(thetas), x, y, lambd)\n",
    "                \n",
    "                thetas[theta_index][row_index][column_index] = temp\n",
    "                \n",
    "                plus_eps = thetas[theta_index][row_index][column_index] + eps\n",
    "                thetas[theta_index][row_index][column_index] = plus_eps\n",
    "                cost_high = cost_function(unroll(thetas), x, y, lambd)\n",
    "                \n",
    "                thetas[theta_index][row_index][column_index] = temp\n",
    "                approx_gradient = (cost_high - cost_low) / float(2 * eps)\n",
    "                \n",
    "                print(f'[{row_index}][{column_index}], check gradient: {approx_gradient:f}, BP gradient: {ds[theta_index][row_index][column_index]:f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8][350], check gradient: 0.000062, BP gradient: 0.000062\n",
      "[8][363], check gradient: -0.000000, BP gradient: -0.000000\n",
      "[18][112], check gradient: -0.000064, BP gradient: -0.000064\n",
      "[1][282], check gradient: 0.000000, BP gradient: 0.000000\n",
      "[5][2], check gradient: 0.000582, BP gradient: 0.000582\n",
      "[6][10], check gradient: -0.000856, BP gradient: -0.000856\n",
      "[9][20], check gradient: -0.001090, BP gradient: -0.001090\n",
      "[7][14], check gradient: 0.001315, BP gradient: 0.001315\n"
     ]
    }
   ],
   "source": [
    "gradient_check([theta_1, theta_2], [D1, D2], x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# back propagate gradients\n",
    "D1, D2 = reshape(back_propagate(thetas, x_train, y_train, lambd=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10][32], check gradient: 0.000003, BP gradient: 0.000003\n",
      "[3][16], check gradient: 0.000000, BP gradient: 0.000000\n",
      "[22][348], check gradient: 0.000009, BP gradient: 0.000009\n",
      "[10][279], check gradient: -0.000020, BP gradient: -0.000020\n",
      "[0][10], check gradient: 0.000706, BP gradient: 0.000706\n",
      "[1][15], check gradient: -0.001211, BP gradient: -0.001211\n",
      "[6][12], check gradient: -0.000238, BP gradient: -0.000238\n",
      "[2][22], check gradient: 0.000023, BP gradient: 0.000023\n"
     ]
    }
   ],
   "source": [
    "gradient_check(np.array([theta_1, theta_2]), [D1, D2], x_train, y_train, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x, y, lambd = 0., maxiter = 30, disp = True):\n",
    "    \n",
    "    theta_1, theta_2 = generate_random_weights()\n",
    "    \n",
    "    thetas = unroll([theta_1, theta_2])\n",
    "\n",
    "    optimized_thetas = scipy.optimize.fmin_cg(cost_function, x0=thetas, fprime=back_propagate,\n",
    "                                args=(x, y, lambd), maxiter=maxiter, disp=disp)\n",
    "    \n",
    "    return reshape(optimized_thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_thetas = train(x_train, y_train, 0., 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_accuracy(learned_thetas, x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_hidden_layer(hidden_layer_theta):\n",
    "    images = hidden_layer_theta\n",
    "    \n",
    "    fig, axs = plt.subplots(5, 5, figsize=(8, 8))\n",
    "    fig.subplots_adjust(wspace=0.025, hspace=0.025)\n",
    "    \n",
    "    axs = axs.flatten()\n",
    "    \n",
    "    for i in range(len(axs)):\n",
    "        ax = axs[i]\n",
    "        ax.imshow(get_image_matrix(images[i]), cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_hidden_layer(learned_thetas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_values = [0, 0.001, 0.01, 0.1, 1., 10., 30.]\n",
    "lambda_tests = {}\n",
    "for i in range(len(lambda_values)):\n",
    "    lambd = lambda_values[i]\n",
    "    \n",
    "    thetas = train(x_train, y_train, lambd, maxiter = 50, disp=False)\n",
    "    accuracy = compute_accuracy(thetas, x_train, y_train)\n",
    "    \n",
    "    lambda_tests[str(lambd)] = {\n",
    "        'lambda': lambd,\n",
    "        'thetas': thetas,\n",
    "        'accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambdas = []\n",
    "accuracies = []\n",
    "lambda_tests.items()\n",
    "for key, value in lambda_tests.items():\n",
    "    print(f\"lambda: {key}, accuracy: {value['accuracy']}\")\n",
    "    lambdas.append(value['lambda'])\n",
    "    accuracies.append(value['accuracy'])\n",
    "    display_hidden_layer(np.array(value[\"thetas\"])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values = np.arange(len(lambdas))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(x_values, accuracies, 'o-')\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"\\u03BB\", fontsize=25)\n",
    "plt.ylabel(\"Accuracy\", fontsize=25)\n",
    "plt.xticks(x_values, lambdas)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
